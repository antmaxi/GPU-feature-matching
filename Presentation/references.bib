@inproceedings{Shakhnarovich2005NearestNeighborMI,
  title={Nearest-Neighbor Methods in Learning and Vision: Theory and Practice (Neural Information Processing)},
  author={Gregory Shakhnarovich and Trevor Darrell and P. Indyk},
  year={2005}
}

@INPROCEEDINGS{LSH_Pan2010,
  author={J. {Pan} and C. {Lauterbach} and D. {Manocha}},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Efficient nearest-neighbor computation for GPU-based motion planning}, 
  year={2010},
  volume={},
  number={},
  pages={2243-2248},}
  
@article{Lowe2004,
  doi = {10.1023/b:visi.0000029664.99615.94},
  url = {https://doi.org/10.1023/b:visi.0000029664.99615.94},
  year = {2004},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {60},
  number = {2},
  pages = {91--110},
  author = {David G. Lowe},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  journal = {International Journal of Computer Vision}
}

@INPROCEEDINGS{orb,
  author={E. {Rublee} and V. {Rabaud} and K. {Konolige} and G. {Bradski}},
  booktitle={2011 International Conference on Computer Vision}, 
  title={ORB: An efficient alternative to SIFT or SURF}, 
  year={2011},
  volume={},
  number={},
  pages={2564-2571},}
  
@InProceedings{lift,
author="Yi, Kwang Moo
and Trulls, Eduard
and Lepetit, Vincent
and Fua, Pascal",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="LIFT: Learned Invariant Feature Transform",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="467--483",
abstract="We introduce a novel Deep Network architecture that implements the full feature point handling pipeline, that is, detection, orientation estimation, and feature description. While previous works have successfully tackled each one of these problems individually, we show how to learn to do all three in a unified manner while preserving end-to-end differentiability. We then demonstrate that our Deep pipeline outperforms state-of-the-art methods on a number of benchmark datasets, without the need of retraining.",
isbn="978-3-319-46466-4"
}


@InProceedings{SURF,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="404--417",
abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
isbn="978-3-540-33833-8"
}

@INPROCEEDINGS{BRISK,
  author={S. {Leutenegger} and M. {Chli} and R. Y. {Siegwart}},
  booktitle={2011 International Conference on Computer Vision}, 
  title={BRISK: Binary Robust invariant scalable keypoints}, 
  year={2011},
  volume={},
  number={},
  pages={2548-2555},}

@inproceedings{MegaDepth,
  	title={MegaDepth: Learning Single-View Depth Prediction from Internet Photos},
  	author={Zhengqi Li and Noah Snavely},
  	booktitle={Computer Vision and Pattern Recognition (CVPR)},
  	year={2018}
}

@misc{ms-coco,
    title={Microsoft COCO: Common Objects in Context},
    author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
    year={2014},
    eprint={1405.0312},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{EuRoC,
  doi = {10.1177/0278364915620033},
  url = {https://doi.org/10.1177/0278364915620033},
  year = {2016},
  month = jan,
  publisher = {{SAGE} Publications},
  volume = {35},
  number = {10},
  pages = {1157--1163},
  author = {Michael Burri and Janosch Nikolic and Pascal Gohl and Thomas Schneider and Joern Rehder and Sammy Omari and Markus W Achtelik and Roland Siegwart},
  title = {The {EuRoC} micro aerial vehicle datasets},
  journal = {The International Journal of Robotics Research}
}

@ARTICLE{Oxford,  author={K. {Mikolajczyk} and C. {Schmid}},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   title={A performance evaluation of local descriptors},   year={2005},  volume={27},  number={10},  pages={1615-1630},}

@article{Learning_to_find,
author = {Yi, Kwang and Trulls, Eduard and Ono, Yuki and Lepetit, Vincent and Salzmann, Mathieu and Fua, Pascal},
year = {2017},
month = {11},
pages = {},
title = {Learning to Find Good Correspondences}
}

@inproceedings{diffpool,
author = {Ying, Rex and You, Jiaxuan and Morris, Christopher and Ren, Xiang and Hamilton, William L. and Leskovec, Jure},
title = {Hierarchical Graph Representation Learning with Differentiable Pooling},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {4805–4815},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS’18}
}
@article{YFCC100M,
author = {Thomee, Bart and Shamma, David A. and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
title = {YFCC100M: The New Data in Multimedia Research},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/2812802},
doi = {10.1145/2812802},
journal = {Commun. ACM},
month = jan,
pages = {64–73},
numpages = {10}
}


@INPROCEEDINGS{sun3d,  author={J. {Xiao} and A. {Owens} and A. {Torralba}},  booktitle={2013 IEEE International Conference on Computer Vision},   title={SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels},   year={2013},  volume={},  number={},  pages={1625-1632},}

@incollection{LF-net,
title = {LF-Net: Learning Local Features from Images},
author = {Ono, Yuki and Trulls, Eduard and Fua, Pascal and Yi, Kwang Moo},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {6234--6244},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7861-lf-net-learning-local-features-from-images.pdf}
}

@article{Sarlin2019a,
abstract = {This paper introduces SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points. Assignments are estimated by solving a differentiable optimal transport problem, whose costs are predicted by a graph neural network. We introduce a flexible context aggregation mechanism based on attention, enabling SuperGlue to reason about the underlying 3D scene and feature assignments jointly. Compared to traditional, hand-designed heuristics, our technique learns priors over geometric transformations and regularities of the 3D world through end-to-end training from image pairs. SuperGlue outperforms other learned approaches and achieves state-of-the-art results on the task of pose estimation in challenging real-world indoor and outdoor environments. The proposed method performs matching in real-time on a modern GPU and can be readily integrated into modern SfM or SLAM systems. The code and trained weights are publicly available at https://github.com/magicleap/SuperGluePretrainedNetwork.},
archivePrefix = {arXiv},
arxivId = {1911.11763},
author = {Sarlin, Paul-Edouard and DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},
eprint = {1911.11763},
file = {:home/anton/Documents/ETH{\_}books/Seminar in Robotics/Marcin/SuperGlue$\backslash$: Learning Feature Matching with Graph Neural Networks.pdf:pdf},
mendeley-groups = {Seminar},
title = {{SuperGlue: Learning Feature Matching with Graph Neural Networks}},
url = {http://arxiv.org/abs/1911.11763},
year = {2019}
}

@inproceedings{RadarRobotCarDatasetICRA2020,
address = {Paris},
author = {Barnes, Dan and Gadd, Matthew and Murcutt, Paul and Newman, Paul and Posner, Ingmar},
title = {The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
url = {https://arxiv.org/abs/1909.01300},
pdf = {https://arxiv.org/pdf/1909.01300.pdf},
year = {2020}
}

@MISC{Sattler12imageretrieval,
    author = {Torsten Sattler and Tobias Weyand and Bastian Leibe and Leif Kobbelt},
    title = { Image Retrieval for Image-Based Localization Revisited},
    year = {2012}
}

@INPROCEEDINGS{cmu,  author={A. {Bansal} and H. {Badino} and D. {Huber}},  booktitle={2014 IEEE Intelligent Vehicles Symposium Proceedings},   title={Understanding how camera configuration and environmental conditions affect appearance-based localization},   year={2014},  volume={},  number={},  pages={800-807},}

@article{Dusmanu2019D2NetAT,
  title={D2-Net: A Trainable CNN for Joint Detection and Description of Local Features},
  author={Mihai Dusmanu and Ignacio Rocco and Tom{\'a}s Pajdla and Marc Pollefeys and Josef Sivic and Akihiko Torii and Torsten Sattler},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.03561}
}

@incollection{R2D2,
title = {R2D2: Reliable and Repeatable Detector and Descriptor},
author = {Revaud, Jerome and De Souza, Cesar and Humenberger, Martin and Weinzaepfel, Philippe},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {12405--12415},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9407-r2d2-reliable-and-repeatable-detector-and-descriptor.pdf}
}

@misc{yang2020ur2kid,
    title={UR2KiD: Unifying Retrieval, Keypoint Detection, and Keypoint Description without Local Correspondence Supervision},
    author={Tsun-Yi Yang and Duy-Kien Nguyen and Huub Heijnen and Vassileios Balntas},
    year={2020},
    eprint={2001.07252},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{HPatches,
author = {Balntas, Vassileios and Lenc, Karel and Vedaldi, Andrea and Mikolajczyk, Krystian},
year = {2017},
month = {04},
pages = {},
title = {HPatches: A benchmark and evaluation of handcrafted and learned local descriptors},
volume = {PP},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2019.2915233}
}

@article{Zhang2019,
abstract = {Establishing correspondences between two images requires both local and global spatial context. Given putative correspondences of feature points in two views, in this paper, we propose Order-Aware Network, which infers the probabilities of correspondences being inliers and regresses the relative pose encoded by the essential matrix. Specifically, this proposed network is built hierarchically and comprises three novel operations. First, to capture the local context of sparse correspondences, the network clusters unordered input correspondences by learning a soft assignment matrix. These clusters are in a canonical order and invariant to input permutations. Next, the clusters are spatially correlated to form the global context of correspondences. After that, the context-encoded clusters are recovered back to the original size through a proposed upsampling operator. We intensively experiment on both outdoor and indoor datasets. The accuracy of the two-view geometry and correspondences are significantly improved over the state-of-the-arts.},
archivePrefix = {arXiv},
arxivId = {1908.04964},
author = {Zhang, Jiahui and Sun, Dawei and Luo, Zixin and Yao, Anbang and Zhou, Lei and Shen, Tianwei and Chen, Yurong and Liao, Hongen and Quan, Long},
doi = {10.1109/ICCV.2019.00594},
eprint = {1908.04964},
file = {:home/anton/Documents/ETH{\_}books/Seminar in Robotics/Marcin/Learning Two-View Correspondences and Geometry
Using Order-Aware Network.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
mendeley-groups = {Seminar},
pages = {5844--5853},
title = {{Learning two-view correspondences and geometry using order-aware network}},
volume = {2019-Octob},
year = {2019}
}

@article{Sarlin2019b,
abstract = {Robust and accurate visual localization is a fundamental capability for numerous applications, such as autonomous driving, mobile robotics, or augmented reality. It remains, however, a challenging task, particularly for large-scale environments and in presence of significant appearance changes. State-of-the-art methods not only struggle with such scenarios, but are often too resource intensive for certain real-time applications. In this paper we propose HF-Net, a hierarchical localization approach based on a monolithic CNN that simultaneously predicts local features and global descriptors for accurate 6-DoF localization. We exploit the coarse-to-fine localization paradigm: We first perform a global retrieval to obtain location hypotheses and only later match local features within those candidate places. This hierarchical approach incurs significant runtime savings and makes our system suitable for real-time operation. By leveraging learned descriptors, our method achieves remarkable localization robustness across large variations of appearance and sets a new state-of-the-art on two challenging benchmarks for large-scale localization.},
archivePrefix = {arXiv},
arxivId = {1812.03506},
author = {Sarlin, Paul Edouard and Cadena, Cesar and Siegwart, Roland and Dymczyk, Marcin},
doi = {10.1109/CVPR.2019.01300},
eprint = {1812.03506},
file = {:home/anton/Documents/ETH{\_}books/Seminar in Robotics/Marcin/From Coarse to Fine$\backslash$: Robust Hierarchical Localization at Large Scale.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Datasets and Evaluation,Deep Learning,Recognition: Detection,Retrieval,Robotics + Driving,Vision A},
mendeley-groups = {Seminar},
pages = {12708--12717},
title = {{From coarse to fine: Robust hierarchical localization at large scale}},
volume = {2019-June},
year = {2019}
}

@inproceedings{Get_out,
  title={Get Out of My Lab: Large-scale, Real-Time Visual-Inertial Localization},
  author={Simon Lynen and Torsten Sattler and Michael Bosse and Joel A. Hesch and Marc Pollefeys and Roland Siegwart},
  booktitle={Robotics: Science and Systems},
  year={2015}
}

@INPROCEEDINGS{2d-3d,
  author={T. {Sattler} and B. {Leibe} and L. {Kobbelt}},
  booktitle={2011 International Conference on Computer Vision}, 
  title={Fast image-based localization using direct 2D-to-3D matching}, 
  year={2011},
  volume={},
  number={},
  pages={667-674},}
  
@misc{cuML,
  title = {{cuML - RAPIDS Machine Learning Library}},
  howpublished = {https://github.com/rapidsai/cuml}},
  %note = {Accessed: 2019-12-12}
}

  
@misc{visual_loc,
  title = {{The Visual Localization Benchmark, www.visuallocalization.net}},
  howpublished = {https://www.visuallocalization.net/}},
}

@misc{GPU_VIO,
    title={Faster than FAST: GPU-Accelerated Frontend for High-Speed VIO},
    author={Balazs Nagy and Philipp Foehn and Davide Scaramuzza},
    year={2020},
    eprint={2003.13493},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@INPROCEEDINGS{cascade_hashing,
  author={J. {Cheng} and C. {Leng} and J. {Wu} and H. {Cui} and H. {Lu}},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Fast and Accurate Image Matching with Cascade Hashing for 3D Reconstruction}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},}
  
@article{DeTone2018SuperPointSI,
  title={SuperPoint: Self-Supervised Interest Point Detection and Description},
  author={Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2018},
  pages={337-33712}
}

